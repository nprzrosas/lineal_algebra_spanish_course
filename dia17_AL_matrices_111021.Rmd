---
title: "Día 17 - Matrices"
author: "Dra. Norma C. Pérez Rosas"
date: '`r format(Sys.time(), "%d/%m/%Y")`'
output:
  pdf_document:
    toc: yes
    toc_depth: '2'
  html_document:
    toc: yes
    toc_depth: 2
---

# Leyes distributivas y asociativas de la multiplicación de matrices 

$$
\mathbf{A}(\mathbf{B}+\mathbf{C}) = \mathbf{A}\mathbf{B} + \mathbf{A} \mathbf{C}
$$

```{python}
#lado izquierdo
import numpy as np
A = np.array([[1, 2], [4, 5]])
print(A)
B = np.array([[4, 5, 8], [3, 1, 2]])
print(B)
C = np.array([[1, 4, 1], [2, 6, 2]])
print(C)
sum_B_C = np.add(B, C)
print(sum_B_C)
mul_A_sum_B_C = np.matmul(A, sum_B_C)
print(mul_A_sum_B_C)
```


```{python}
#lado derecho
import numpy as np
A = np.array([[1, 2], [4, 5]])
print(A)
B = np.array([[4, 5, 8], [3, 1, 2]])
print(B)
C = np.array([[1, 4, 1], [2, 6, 2]])
print(C)
mul_A_B = np.matmul(A, B)
print(mul_A_B)
mul_A_C = np.matmul(A, C)
print(mul_A_C)
sum_AB_AC = np.add(mul_A_B, mul_A_C)
print(sum_AB_AC)
```

$$
(\mathbf{A} + \mathbf{B})\mathbf{C} = \mathbf{A}\mathbf{C} + \mathbf{B} \mathbf{C}
$$


```{python}
#lado izquierdo
import numpy as np
A = np.array([[1, 2], [4, 5]])
print(A)
B = np.array([[4, 5], [3, 1]])
print(B)
C = np.array([[1, 4], [6, 2]])
print(C)
sum_A_B = np.add(A, B)
print(sum_A_B)
mult_sum_A_B_C = np.matmul(sum_A_B, C)
print(mult_sum_A_B_C)
```

```{python}
#lado derecho
import numpy as np
A = np.array([[1, 2], [4, 5]])
print(A)
B = np.array([[4, 5], [3, 1]])
print(B)
C = np.array([[1, 4], [6, 2]])
print(C)
mult_A_C = np.matmul(A, C)
print(mult_A_C)
mult_B_C = np.matmul(B, C)
print(mult_B_C)
sum_mult_AC_BC = np.add(mult_A_C, mult_B_C)
print(sum_mult_AC_BC)
```

$$
\mathbf{A} \mathbf{B} \neq \mathbf{B}\mathbf{A}
$$

```{python}
#lado derecho
import numpy as np
A = np.array([[1, 2], [4, 5]])
print(A)
B = np.array([[4, 5], [3, 1]])
print(B)
mult_A_B = np.matmul(A, B)
print(mult_A_B)
mult_B_A = np.matmul(B, A)
print(mult_B_A)
```

Dados dos valores escalares, $a$ y $b$, sí el producto $ab=0$ entonces nosotros podemos estar seguros que alguno de los valores son cero o que los dos valores son cero. En la multiplicación de matrices este no es el caso. Es posible tener dos matrices no nulas que cuando se multipliquen nos den cero. 

## Post y pre multiplicación 

Una de las primeras reglas aprendidas en nuestra educación matemática fue que al multiplicar dos lados de una ecuación por el mismo término no cambia la ecuación. Por ejemplo, sí 

$a = b$

Entonces se puede multiplicar ambos lados de la ecuación por $x$ para producir:

$xa=xb$

Nosotros podemos hacer un operación similar con matrices siempre y cuando estemos conscientes de algunas restricciones: considere la siguiente ecuación de matrices donde se ha indicado el tamaño de cada matriz,

$\mathbf{A}_{m\times n}=\mathbf{B}_{m\times p}\mathbf{B}_{p\times n}$

Suponga que nosotros deseamos multiplicar ambos lados por la matriz $\mathbf{X}$. La primera cosa que debe notar es que  para que pueda efectuarse la operación, el número de columnas de $\mathbf{X}$ debe coincidir con el número de finales en $\mathbf{A}$

$\mathbf{X}_{q\times m}\mathbf{A}_{m\times n}=\mathbf{X}_{q\times m}\mathbf{B}_{m\times p}\mathbf{C}_{p\times n}$

A esto se le llama pre-multiplicación dónde el término $\mathbf{X}$ aparece en el lado izquierdo de cada lado de la ecuación. También es posible la post-multiplicación. En este caso el número de filas de $\mathbf{X}$ debe coincidir con el número de columnas de $\mathbf{A}$. Es decir, 


$\mathbf{A}_{m\times n}\mathbf{X}_{n\times q}=\mathbf{B}_{m\times p}\mathbf{C}_{p\times n}\mathbf{X}_{n\times q}$

## Traspuesta 

La transpuesta del produccto de dos o más matrices es igual al producto de sus transpuestas en orden reverso 

$(\mathbf{A}\mathbf{B}\mathbf{C})^T=\mathbf{C}^T\mathbf{B}^T\mathbf{A}^T$

```{python}
#lado izquierdo
import numpy as np
A = np.array([[1, 2], [4, 5]])
#print(A)
B = np.array([[4, 5], [3, 1]])
#print(B)
C = np.array([[1, 4], [6, 2]])
#print(C)
mult_AB = np.matmul(A, B)
mult_AB_C = np.matmul(mult_AB, C)
mult_AB_C_trans = np.transpose(mult_AB_C)
print(mult_AB_C_trans)
```

```{python}
#lado derecho
import numpy as np
A = np.array([[1, 2], [4, 5]])
#print(A)
B = np.array([[4, 5], [3, 1]])
#print(B)
C = np.array([[1, 4], [6, 2]])
#print(C)
A_T = np.transpose(A)
#print(A_T)
B_T = np.transpose(B)
#print(B_T)
C_T = np.transpose(C)
#print(C_T)
mult_CT_BT = np.matmul(C_T, B_T)
mult_CT_BT_AT = np.matmul(mult_CT_BT, A_T)
print(mult_CT_BT_AT)
```
## Matriz permutación  


Un clase importante de matrices es la **matriz permutación**. Esta matriz, es una matriz cuadrada cuyas entradas son todas ceros y unos con un sólo uno cada fila y en cada columna. A partir de esta definición debe ser evidente que la matriz identidad $\mathbf{I}$ es una matriz permutación. Las matrices permutación tienen algunas propiedades interesantes. Una de ellas es la habilidad de rearreglar filas en una matriz objetivo. 

Considere la matriz

```{=tex}
\begin{equation*}
\mathbf{P} =
\begin{pmatrix}
0 & 0 & 1 & 0\\
0 & 1 & 0 & 0\\
0 & 0 & 0 & 1\\
1 & 0 & 0 & 0\\
\end{pmatrix} 
\end{equation*}
```

Multiplicando esa matriz por la siguiente matriz objetivo:

```{=tex}
\begin{equation*}
\mathbf{A} =
\begin{pmatrix}
1 & 1 & 1 & 1\\
2 & 2 & 2 & 2\\
3 & 3 & 3 & 3\\
4 & 4 & 4 & 4\\
\end{pmatrix} 
\end{equation*}
```


Produce la siguiente matriz 

```{=tex}
\begin{equation*}
\mathbf{PA} =
\begin{pmatrix}
3 & 3 & 3 & 3\\
2 & 2 & 2 & 2\\
4 & 4 & 4 & 4\\
1 & 1 & 1 & 1\\
\end{pmatrix} 
\end{equation*}
```

```{python}
#matriz permutación
import numpy as np
P = np.array([[0, 0, 1, 0], [0, 1, 0, 0], [0, 0, 0, 1], [1, 0, 0, 0]])
print(P)
T = np.array([[1, 1, 1, 1], [2, 2, 2, 2], [3, 3, 3, 3], [4, 4, 4, 4]])
print(T)
mult_P_T = np.matmul(P, T)
print(mult_P_T)
```

Una pre-multiplicación por una matriz permutación opera sobre las filas de la matriz. La operación sobre las columnas se alcanza con una post-multiplicación con una matriz permutación. 


```{python}
#matriz permutación
import numpy as np
P = np.array([[0, 0, 1, 0], [0, 1, 0, 0], [0, 0, 0, 1], [1, 0, 0, 0]])
print(P)
T = np.array([[1, 2, 3, 4], [1, 2, 3, 4], [1, 2, 3, 4], [1, 2, 3, 4]])
print(T)
mult_T_P = np.matmul(T, P)
print(mult_T_P)
```

# Inversa de una matriz 

La inversa de una matriz es análoga a la división escalar. Sea $\mathbf{A}$ una matriz de $n \times n$, si una matriz $\mathbf{B}$ existe de forma tal que 

$\mathbf{AB}=\mathbf{BA}=\mathbf{I}$

entonces $\mathbf{B}$ es llamada la **inversa** de $\mathbf{A}$ es denotada por $\mathbf{A}^{-1}$.


**Ejemplo:** 

Sí 


$$
\mathbf{A}=\left[
\begin{array}{cc}
2 & 3  \\
5 & 8  \\
\end{array}
\right]
$$

Entonces:

$$
\mathbf{A}^{-1}=\left[
\begin{array}{cc}
8 & -3  \\
-5 & 2  \\
\end{array}
\right]
$$

Esto es, $\mathbf{A}^{-1}\mathbf{A}=\mathbf{I}$ y $\mathbf{A}\mathbf{A}^{-1}=\mathbf{I}$.

Las inversas sólo pueden calcularse para matrices cuadradas, aunque hay una generalización de la inversa llamada **pseudo inversa** que puede ser aplicada a matrices no cuadradas. No todas las matrices tienen inversa y esas matrices son llamadas **singulares**. Una matriz que tiene inversa is llamada invertible o más comunmente **no singulares**


Para matrices de $2 \times 2$ hay una forma conveniente de calcular la inversa.

Si

$$
\mathbf{A}=\left[
\begin{array}{cc}
a & b  \\
c & d  \\
\end{array}
\right]
$$

Entonces

$$
\mathbf{A}^{-1}=\frac{1}{ad-bc}\left[
\begin{array}{cc}
d & -b  \\
-c & a  \\
\end{array}
\right]
$$

**Ejemplo:**


$$
\mathbf{A}=\left[
\begin{array}{cc}
3 & 4  \\
5 & 8  \\
\end{array}
\right]
$$

$$
\mathbf{A}^{-1}=\frac{1}{(3)(8)-(4)(5)}\left[
\begin{array}{cc}
8 & -4  \\
-5 & 3  \\
\end{array}
\right] = \frac{1}{4}\left[
\begin{array}{cc}
8 & -4  \\
-5 & 3  \\
\end{array}
\right]=\left[
\begin{array}{cc}
2 & -1  \\
-5/4 & 3/4  \\
\end{array}
\right]
$$


```{r}
matriz <- matrix(c(3, 5, 4, 8), ncol = 2)
matriz
inversa <- solve(matriz)
inversa
inversa %*% matriz
```


```{python}
#matriz permutación
import numpy as np
A = np.array([[3, 4], [5, 8]])
print(A)
A_inversa = np.linalg.inv(A)
print(A_inversa)
```

# Código en LaTex

Para producir la siguiente expresión se uso este código en LaTex

![Código en LaTeX](latex1.PNG)


$$
\mathbf{A}^{-1}=\frac{1}{(3)(8)-(4)(5)}\left[
\begin{array}{cc}
8 & -4  \\
-5 & 3  \\
\end{array}
\right] = \frac{1}{4}\left[
\begin{array}{cc}
8 & -4  \\
-5 & 3  \\
\end{array}
\right]=\left[
\begin{array}{cc}
2 & -1  \\
-5/4 & 3/4  \\
\end{array}
\right]
$$

![Código en LaTeX](latex2.PNG)


\begin{equation*}
\mathbf{P} =
\begin{pmatrix}
3 & 3 & 3 & 3\\
2 & 2 & 2 & 2\\
4 & 4 & 4 & 4\\
1 & 1 & 1 & 1\\
\end{pmatrix} 
\end{equation*}





# Asistencia 

From Melanie Mondragón to Everyone:  11:30 AM

Presente

From Irving Barreto to Everyone:  11:30 AM

Presnete

From Fernanda Pilón to Everyone:  11:30 AM

Presente

From Emmanuel Gonzalez to Everyone:  11:34 AM

Presente

From David Dorantes to Everyone:  11:34 AM

presenté

From Diego Nicolas to Everyone:  11:35 AM

presente

From Frida Cuevas to Everyone:  11:35 AM

Presente

From Ivan Delgado to Everyone:  11:35 AM

Presente

From wenddy Ballona to Everyone:  11:35 AM

Presente

From Maria Fernanda Garcia to Everyone:  11:35 AM

presente

From Andrew Flores Yebra to Everyone:  11:35 AM

Presente

From José María Garduño to Everyone:  11:35 AM

Presente

From Pérez David to Everyone:  11:36 AM

Presente

From Itzel Aurora Bravo Santos to Everyone:  11:36 AM

Presente

From Fernanda Cardenas to Everyone:  11:36 AM

Presente

From Jorge Ambrosio to Everyone:  11:36 AM

Presente

From Víctor Jerónimo to Everyone:  11:38 AM

Presente

From Gaeta to Everyone:  12:01 PM

Presente
